name: scrape-online-newspapers-for-news

on:
  push:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest
    steps:

      - name: checkout repo content
        uses: actions/checkout@v2 # checkout the repository content to github runner

      - name: setup python
        uses: actions/setup-python@v2
        with:
          python-version: '3.9.0' # install the python version needed

      - name: install pipenv and dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install --upgrade pipenv wheel
      - id: cache-pipenv
        uses: actions/cache@v1
        with:
          path: ~/.local/share/virtualenvs
          key: ${{ runner.os }}-pipenv-${{ hashFiles('**/Pipfile.lock') }}

      - name: Install dependencies
        if: steps.cache-pipenv.outputs.cache-hit != 'true'
        run: |
          pipenv install --dev
      - name: execute py script # run ngrnewscorpus.py to get the latest data

        run: pipenv run python newsscrapy.py

      - name: commit files
        run: |
          git add ./data*
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git commit -m "update data"
      - name: push changes
        uses: ad-m/github-push-action@v0.6.0
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: main
